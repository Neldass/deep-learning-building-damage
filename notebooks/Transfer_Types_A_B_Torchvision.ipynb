{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13282903",
   "metadata": {},
   "source": [
    "# ğŸ”„ Transfer Learning Type A & B avec modÃ¨les torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944b8fe",
   "metadata": {},
   "source": [
    "\n",
    "Ce notebook teste plusieurs modÃ¨les prÃ©-entraÃ®nÃ©s (`torchvision.models`) pour la classification binaire post-ouragan (Flooded/Damaged vs Undamaged), selon :\n",
    "\n",
    "- **Type A** : Feature extractor (gelÃ©) + nouveau classifieur\n",
    "- **Type B** : Fine-tuning complet (non gelÃ©) + nouveau classifieur\n",
    "\n",
    "ModÃ¨les testÃ©s :\n",
    "- `resnet18`\n",
    "- `alexnet`\n",
    "- `densenet121`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = \"Post-hurricane\"\n",
    "img_size = 150\n",
    "batch_size = 32\n",
    "num_epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train_another\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"validation_another\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(model_name='resnet18', type_B=False):\n",
    "    base_model = getattr(models, model_name)(pretrained=True)\n",
    "\n",
    "    # Geler les couches si Type A\n",
    "    if not type_B:\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Adapter le classifier selon l'architecture\n",
    "    if model_name.startswith(\"resnet\"):\n",
    "        in_features = base_model.fc.in_features\n",
    "        base_model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "    elif model_name.startswith(\"alexnet\") or model_name.startswith(\"vgg\"):\n",
    "        in_features = base_model.classifier[-1].in_features\n",
    "        base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "    elif model_name.startswith(\"densenet\"):\n",
    "        in_features = base_model.classifier.in_features\n",
    "        base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Architecture non supportÃ©e pour ce script\")\n",
    "\n",
    "    return base_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate(model):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "    # Ã‰valuation\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            y_prob.extend(probs)\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    y_pred = (np.array(y_prob) > 0.5).astype(int)\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    print(f\"AUC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ” Test de ResNet18 Type A (gelÃ©)\n",
    "print(\"ğŸ§ª ResNet18 - Type A (gelÃ©)\")\n",
    "model_resnet18_A = create_model('resnet18', type_B=False)\n",
    "train_and_evaluate(model_resnet18_A)\n",
    "\n",
    "# ğŸ” Test de ResNet18 Type B (fine-tuning)\n",
    "print(\"ğŸ§ª ResNet18 - Type B (fine-tuning)\")\n",
    "model_resnet18_B = create_model('resnet18', type_B=True)\n",
    "train_and_evaluate(model_resnet18_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ” Test de DenseNet121 Type A\n",
    "print(\"ğŸ§ª DenseNet121 - Type A (gelÃ©)\")\n",
    "model_densenet_A = create_model('densenet121', type_B=False)\n",
    "train_and_evaluate(model_densenet_A)\n",
    "\n",
    "# ğŸ” Test de DenseNet121 Type B\n",
    "print(\"ğŸ§ª DenseNet121 - Type B (fine-tuning)\")\n",
    "model_densenet_B = create_model('densenet121', type_B=True)\n",
    "train_and_evaluate(model_densenet_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ” Test de AlexNet Type A\n",
    "print(\"ğŸ§ª AlexNet - Type A (gelÃ©)\")\n",
    "model_alexnet_A = create_model('alexnet', type_B=False)\n",
    "train_and_evaluate(model_alexnet_A)\n",
    "\n",
    "# ğŸ” Test de AlexNet Type B\n",
    "print(\"ğŸ§ª AlexNet - Type B (fine-tuning)\")\n",
    "model_alexnet_B = create_model('alexnet', type_B=True)\n",
    "train_and_evaluate(model_alexnet_B)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
